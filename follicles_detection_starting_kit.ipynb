{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection and classification of ovarian follicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intro text motivating the challenge and explaining the importance of studying ovarian follicles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This challenge aims at building a machine learning solution for automated classification and counting of follicles on histological sections.\n",
    "We will distinguish here 4 categories of follicles from smaller to larger follicles: Primordial, Primary, Secondary, Tertiary. One of the difficulty lies in the fact that there is a great disparity of size between all the follicles. Another one is that most of pre-trained classifier are trained on daily life objets, not biological tissues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data consist of 34 images of histological sections taken on 6 mice ovaries. __29 sections in the train__ dataset and __5 sections in the test__ dataset. Each section has been annotated with ground truth follicles locations and categories. Bounding boxes coordinates and class labels are stored in a csv file named labels.csv, one for each train and test set.\n",
    "A Negative class has also been created with bounding boxes of various sizes on locations where there is no positive examples of follicles from the 4 retained categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These modules and libraries must be imported to properly run the notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First uncomment the following line to download the data using this python script. It will create a data folder inside which will be placed the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a feel of what the data look like, let's visualize an image of a section and the corresponding annotations. \n",
    "\n",
    "First we need to be able to read and extract bounding boxes coordinates and class names from the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display labels.csv as a pandas dataframe for train set\n",
    "train_labels = pd.read_csv(os.path.join(\"data\", \"train\", \"labels.csv\"))\n",
    "train_labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function extract boxes coordinates for true locations (ground truth annotations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_true_locations(path, image_filename):\n",
    "    \"\"\"Return list of {bbox, class, proba}.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.loc[df[\"filename\"] == image_filename] \n",
    "    locations = []\n",
    "    for _, row in df.iterrows():\n",
    "        loc_dict = {\n",
    "            \"bbox\": (row['xmin'], row['ymin'], row['xmax'], row['ymax']),\n",
    "            \"class\": row[\"class\"],\n",
    "            \"proba\": 1\n",
    "        }\n",
    "        locations.append(loc_dict)\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function that diplays the image and bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_section_and_locations(section, locations):\n",
    "    linewidth=3\n",
    "    class_to_color = {\n",
    "        \"Negative\": \"grey\", \n",
    "        \"Primordial\": \"blue\", \n",
    "        \"Primary\": \"red\", \n",
    "        \"Secondary\": \"green\", \n",
    "        \"Tertiary\": \"purple\"\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(section)\n",
    "    ax = plt.gca()\n",
    "    for location in locations:\n",
    "        box = location[\"bbox\"]\n",
    "        class_ = location[\"class\"]\n",
    "        proba = location[\"proba\"]\n",
    "\n",
    "        color = class_to_color[class_]\n",
    "        text = \"{}: {:.2f}\".format(class_, proba)\n",
    "        linestyle = \"-\" if proba == 1 else \"--\"\n",
    "\n",
    "        x1, y1, x2, y2 = box\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        patch = plt.Rectangle(\n",
    "            [x1, y1], w, h, fill=False, edgecolor=color, linewidth=linewidth, linestyle=linestyle\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "        ax.text(\n",
    "            x1,\n",
    "            y1,\n",
    "            text,\n",
    "            bbox={\"facecolor\": color, \"alpha\": 1},\n",
    "            clip_box=ax.clipbox,\n",
    "            clip_on=True,\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_folder = os.path.abspath(\"\")\n",
    "DATA_FOLDER = os.path.join(this_folder, \"data\")\n",
    "MODELS_FOLDER = os.path.join(this_folder, \"models\")\n",
    "\n",
    "IMAGE_TO_ANALYSE = 'D-1M02-2.jpg'\n",
    "\n",
    "CLASSES = ['Negative', 'Primordial', 'Primary', 'Secondary', 'Tertiary']\n",
    "CLASS_TO_INDEX = {\n",
    "            \"Negative\": 0,\n",
    "            \"Primordial\": 1,\n",
    "            \"Primary\": 2,\n",
    "            \"Secondary\": 3,\n",
    "            \"Tertiary\": 4,\n",
    "}\n",
    "INDEX_TO_CLASS = {value: key for key, value in CLASS_TO_INDEX.items()}\n",
    "\n",
    "#section = Image.open(os.path.join(DATA_FOLDER, \"train\", IMAGE_TO_ANALYSE))\n",
    "section = plt.imread(os.path.join(DATA_FOLDER, \"train\", IMAGE_TO_ANALYSE))\n",
    "true_locations = load_true_locations(os.path.join(DATA_FOLDER, \"train\", 'labels.csv'), IMAGE_TO_ANALYSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_section_and_locations(section, true_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to change IMAGE_TO_ANALYSE name to display other examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is the size distribution of all the ground truth bounding boxes in the train set ?\n",
    "First we make a list of all those locations, and then we count by class and visualize histograms of the width of bounding boxes per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_true_locations(path):\n",
    "    labels = pd.read_csv(path)\n",
    "    all_locations = []\n",
    "    for _, row in labels.iterrows():\n",
    "        loc_dict = {\n",
    "            \"bbox\": (row['xmin'], row['ymin'], row['xmax'], row['ymax']),\n",
    "            \"class\": row[\"class\"],\n",
    "            \"proba\": 1\n",
    "        }\n",
    "        all_locations.append(loc_dict)\n",
    "    return all_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all locations in train set\n",
    "all_locations_train = all_true_locations(os.path.join(DATA_FOLDER, \"train\", 'labels.csv'))\n",
    "len(all_locations_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of boxes per class\n",
    "print('Number of boxes per class in the train set:')\n",
    "for class_ in CLASSES:\n",
    "    box_count = [1 for location in all_locations_train if location['class']==class_]\n",
    "    print(f'{class_}: {len(box_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of bboxes width\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, class_ in enumerate(CLASSES):\n",
    "    width_list = [location['bbox'][2]-location['bbox'][0]\n",
    "        for location in all_locations_train if location['class']==class_\n",
    "    ]\n",
    "    ax = plt.subplot(5, 1, i+1)\n",
    "    plt.hist(width_list)\n",
    "    plt.title(f'Width of boxes for {class_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that follicles are arranged in this order of their size : Primordial < Primary < Secondary < Tertiary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen strategy for the baseline algorithm is a random window cropping followed by a multiclass classification at each extracted window.\n",
    "First let's build and train the classifier. Here we take a pretrained model on Imagenet and freeze its weights. Then we only train the last fully-connected layer with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image shape for classifier\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "\n",
    "# Building of a classification model\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=IMG_SHAPE, include_top=False, weights=\"imagenet\"\n",
    "    )\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting all training examples from images and creating Xtrain and ytrain for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model takes as input a tensor (M, 224, 224, 3) and\n",
    "# for each image, a class encoded as an integer.\n",
    "# Consequently we need to build these images from the files on disc\n",
    "\n",
    "X_image_paths = [os.path.join(DATA_FOLDER, \"train\", filename)\n",
    "    for filename in train_labels[\"filename\"].unique()\n",
    "]\n",
    "y_true_locations = [load_true_locations(os.path.join(DATA_FOLDER, \"train\", 'labels.csv'), filename)\n",
    "    for filename in train_labels[\"filename\"].unique()\n",
    "]\n",
    "\n",
    "thumbnails = []\n",
    "expected_predictions = []\n",
    "\n",
    "for filepath, locations in zip(X_image_paths, y_true_locations):\n",
    "    print(f\"reading {filepath}\")\n",
    "    image = Image.open(filepath)\n",
    "    for loc in locations:\n",
    "        class_, bbox = loc[\"class\"], loc[\"bbox\"]\n",
    "        prediction = CLASS_TO_INDEX[class_]\n",
    "        expected_predictions.append(prediction)\n",
    "        thumbnail = image.crop(bbox)\n",
    "        thumbnail = thumbnail.resize((224, 224))\n",
    "        thumbnail = np.asarray(thumbnail)\n",
    "        thumbnails.append(thumbnail)\n",
    "X_for_classifier = np.array(thumbnails)\n",
    "y_for_classifier = np.array(expected_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_classifier.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_for_classifier, y_for_classifier, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "MODEL_NAME_FOR_PREDICTION = \"classifier3\"\n",
    "model = tf.keras.models.load_model(os.path.join(MODELS_FOLDER, MODEL_NAME_FOR_PREDICTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image, model):\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((224,224))\n",
    "    image = np.array(image)\n",
    "    image = tf.reshape(image, (1,224,224,3))\n",
    "    pred = model.predict(image)\n",
    "    return np.argmax(pred), np.max(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = plt.imread(os.path.join(DATA_FOLDER, 'test', 'D-1M06-1.jpg'))\n",
    "#plt.imshow(section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some predictions on cropped images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = section[8700:10700, 7250:9250]\n",
    "plt.imshow(window)\n",
    "\n",
    "pred = predict_image(window, model)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = section[500:1900, 9500:10800]\n",
    "plt.imshow(window)\n",
    "\n",
    "pred = predict_image(window, model)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = section[2000:4000, 3000:5000]\n",
    "plt.imshow(window)\n",
    "\n",
    "pred = predict_image(window, model)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv(os.path.join(\"data\", \"test\", \"labels.csv\"))\n",
    "test_labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_image_paths = [os.path.join(DATA_FOLDER, \"test\", filename)\n",
    "    for filename in test_labels[\"filename\"].unique()\n",
    "]\n",
    "ytest_true_locations = [load_true_locations(os.path.join(DATA_FOLDER, \"test\", 'labels.csv'), filename)\n",
    "    for filename in test_labels[\"filename\"].unique()\n",
    "]\n",
    "\n",
    "thumbnails = []\n",
    "expected_predictions = []\n",
    "\n",
    "for filepath, locations in zip(Xtest_image_paths, ytest_true_locations):\n",
    "    print(f\"reading {filepath}\")\n",
    "    image = Image.open(filepath)\n",
    "    for loc in locations:\n",
    "        class_, bbox = loc[\"class\"], loc[\"bbox\"]\n",
    "        prediction = CLASS_TO_INDEX[class_]\n",
    "        expected_predictions.append(prediction)\n",
    "        thumbnail = image.crop(bbox)\n",
    "        thumbnail = thumbnail.resize((224, 224))\n",
    "        thumbnail = np.asarray(thumbnail)\n",
    "        thumbnails.append(thumbnail)\n",
    "Xtest_for_classifier = np.array(thumbnails)\n",
    "ytest_for_classifier = np.array(expected_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the classifier\n",
    "We use model.evaluate with test data to evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(Xtest_for_classifier, ytest_for_classifier)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#model.save(os.path.join(MODELS_FOLDER, \"classifier3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(Xtest_for_classifier)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_for_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "con_mat = confusion_matrix(ytest_for_classifier, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=con_mat)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(ytest_for_classifier, preds, target_names=[\"Negative\", \"Primordial\", \"Primary\", \"Secondary\", \"Tertiary\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy here is to generate random windows on test images and pass them through the classifier. We can choose different mean (window_size) and the window size will be drawn from a normal distribution with this mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random window generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_windows_for_image(image, window_sizes, num_windows):\n",
    "    \"\"\"create list of bounding boxes of varying sizes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "    window_sizes : list of int\n",
    "        exemple [200, 1000, 2000]\n",
    "        sizes of windows to use\n",
    "    num_windows : list of int\n",
    "        example [1000, 100, 100]\n",
    "        how many boxes of each window_size should be created ?\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(window_sizes) == len(num_windows)\n",
    "    image_height, image_width, _ = image.shape\n",
    "    all_boxes = []\n",
    "\n",
    "    for size, n_boxes in zip(window_sizes, num_windows):\n",
    "        mean = size\n",
    "        std = 0.15 * size\n",
    "\n",
    "        for _ in range(n_boxes):\n",
    "            width = np.random.normal(mean, std)\n",
    "            x1 = np.random.randint(0, image_width)\n",
    "            y1 = np.random.randint(0, image_height)\n",
    "\n",
    "            bbox = (x1, y1, x1 + width, y1 + width)\n",
    "            all_boxes.append(bbox)\n",
    "    return all_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_probas_to_locations(probas, boxes):\n",
    "    \"\"\"\n",
    "    create list of locations: list of dict\n",
    "    location: dict(class, proba, bbox)\n",
    "    \n",
    "    \"\"\"\n",
    "    top_index, top_proba = np.argmax(probas, axis=1), np.max(probas, axis=1)\n",
    "    predicted_locations = []\n",
    "    for index, proba, box in zip(top_index, top_proba, boxes):\n",
    "        if index != 0:\n",
    "            predicted_locations.append(\n",
    "                {\"class\": INDEX_TO_CLASS[index], \"proba\": proba, \"bbox\": box}\n",
    "            )\n",
    "    return predicted_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on windows and filtering of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_predictions(predicted_locations, proba_threshold=0.8):\n",
    "    def should_keep_prediction(class_, proba):\n",
    "        if class_ == \"Negative\":\n",
    "            return False\n",
    "        if proba < proba_threshold:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    selected_locations = [\n",
    "        prediction\n",
    "        for prediction in predicted_locations\n",
    "        if should_keep_prediction(prediction[\"class\"], prediction[\"proba\"])\n",
    "    ]\n",
    "\n",
    "    return selected_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_locations = filter_predictions(predicted_locations, proba_threshold=0.80)\n",
    "print(len(selected_locations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_section_and_locations(section, selected_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_TO_ANALYSE = 'D-1M06-5.jpg'\n",
    "#section = Image.open(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE))\n",
    "section = plt.imread(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE))\n",
    "true_locations = load_true_locations(os.path.join(DATA_FOLDER, \"test\", 'labels.csv'), IMAGE_TO_ANALYSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_section_and_locations(section, true_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_locations = []\n",
    "#for width in [800, 1000, 2000, 3000]:\n",
    "#    predicted_locations += predict_locations_for_windows(section, window_size=width, model=model, num_windows=2000)\n",
    "#len(predicted_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cropped_images(image, boxes, crop_size):\n",
    "    \"\"\"Crop subimages in large image and resize them to a single size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array of shape (height, width, depth)\n",
    "    boxes : list of tuple\n",
    "        each element in the list is (xmin, ymin, xmax, ymax)\n",
    "    crop_size : tuple(2)\n",
    "        size of the returned cropped images\n",
    "        ex: (224, 224)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cropped_images : tensor\n",
    "        example shape (N_boxes, 224, 224, 3)\n",
    "\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    images_tensor = [tf.convert_to_tensor(image)]\n",
    "    # WARNING: tf.convert_to_tensor([image])   does not seem to work..\n",
    "    boxes_for_tf = [\n",
    "        (y1 / height, x1 / width, y2 / height, x2 / width) for x1, y1, x2, y2 in boxes\n",
    "    ]\n",
    "    box_indices = [0] * len(boxes_for_tf)\n",
    "    cropped_images = tf.image.crop_and_resize(\n",
    "        images_tensor,\n",
    "        boxes_for_tf,\n",
    "        box_indices,\n",
    "        crop_size,\n",
    "        method=\"bilinear\",\n",
    "        extrapolation_value=0,\n",
    "        name=None,\n",
    "    )\n",
    "    return cropped_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path, boxes_sizes=[3000,1000,300], boxes_num = [200,500,2000]):\n",
    "    image = plt.imread(image_path)\n",
    "    boxes = generate_random_windows_for_image(image, boxes_sizes, boxes_num)\n",
    "    cropped_images = build_cropped_images(\n",
    "        image, boxes, crop_size=IMG_SHAPE[0:2]\n",
    "    )\n",
    "    predicted_probas = model.predict(cropped_images)\n",
    "    predicted_locations = convert_probas_to_locations(predicted_probas, boxes)\n",
    "    return predicted_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_locations = predict_single_image(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE), boxes_sizes=[2000,1000,300], boxes_num = [1000,1000,2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_locations = filter_predictions(predicted_locations, proba_threshold=0.70)\n",
    "print(len(selected_locations))\n",
    "display_section_and_locations(section, selected_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IOU-NMS to remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    \"\"\"Computes pairwise IOU matrix for given two sets of boxes\n",
    "\n",
    "    Arguments:\n",
    "      boxes1: A tensor with shape `(N, 4)` representing bounding boxes\n",
    "        where each box is of the format `[x, y, x2, y2]`.\n",
    "        boxes2: A tensor with shape `(M, 4)` representing bounding boxes\n",
    "        where each box is of the format `[x, y, xmax, ymax]`.\n",
    "\n",
    "    Returns:\n",
    "      pairwise IOU matrix with shape `(N, M)`, where the value at ith row\n",
    "        jth column holds the IOU between ith box and jth box from\n",
    "        boxes1 and boxes2 respectively.\n",
    "    \"\"\"\n",
    "    lu = np.maximum(boxes1[:, None, :2], boxes2[:, :2])\n",
    "    rd = np.minimum(boxes1[:, None, 2:], boxes2[:, 2:])\n",
    "    intersection = np.maximum(0.0, rd - lu)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1[:,2] - boxes1[:, 0]) * (boxes1[:,3] - boxes1[:, 1])\n",
    "    boxes2_area = (boxes2[:,2] - boxes2[:, 0]) * (boxes2[:,3] - boxes2[:, 1])\n",
    "    union_area = np.maximum(\n",
    "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
    "    )\n",
    "    return np.clip(intersection_area / union_area, 0.0, 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMS(selected_locations, iou_threshold=0.4):\n",
    "    selected_locations_NMS = []\n",
    "    selected_locations_sorted = list(sorted(selected_locations, key=itemgetter('proba'), reverse=True))\n",
    "    # boxes_sorted = np.array([location['bbox'] for location in selected_locations_sorted])\n",
    "    while len(selected_locations_sorted) !=0:\n",
    "        best_box = selected_locations_sorted.pop(0)\n",
    "        selected_locations_NMS.append(best_box)\n",
    "        best_box_coords = np.array(best_box[\"bbox\"]).reshape(1,-1)\n",
    "        other_boxes_coords = np.array([location['bbox'] for location in selected_locations_sorted]).reshape(-1,4)\n",
    "        ious = compute_iou(best_box_coords, other_boxes_coords)\n",
    "        for i, iou in reversed(list(enumerate(ious[0]))):           \n",
    "            if iou > iou_threshold:\n",
    "                selected_locations_sorted.pop(i)\n",
    "    return selected_locations_NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_locations_NMS = NMS(selected_locations, iou_threshold=0.2)\n",
    "len(selected_locations_NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_locations_NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_section_and_locations(section, selected_locations_NMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_bbox(bbox, list_of_bboxes, iou_threshold):\n",
    "    \"\"\"\n",
    "    \n",
    "    Return index, success\n",
    "        index = index of bbox with highest iou\n",
    "        success = if matching iou is greater than threshold\n",
    "    \"\"\"\n",
    "    ious = compute_iou(np.array([bbox]), np.array(list_of_bboxes))[0, :]\n",
    "    index, maximum = np.argmax(ious), np.max(ious)\n",
    "    return index, maximum > iou_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall(true_locations, predicted_locations, iou_threshold=0.3):\n",
    "    classes = [\n",
    "        \"Primordial\",\n",
    "        \"Primary\",\n",
    "        \"Secondary\",\n",
    "        \"Tertiary\",\n",
    "    ]\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    thresholds = {}\n",
    "    for predicted_class in classes:\n",
    "        true_boxes = [\n",
    "            location[\"bbox\"]\n",
    "            for location in true_locations\n",
    "            if location[\"class\"] == predicted_class\n",
    "        ]\n",
    "        if not true_boxes:\n",
    "            continue\n",
    "\n",
    "        pred_boxes = [\n",
    "            (location[\"bbox\"], location[\"proba\"])\n",
    "            for location in sorted(predicted_locations, key=lambda loc: loc[\"proba\"], reverse=True)\n",
    "            if location[\"class\"] == predicted_class\n",
    "        ]\n",
    "\n",
    "        precision = []\n",
    "        recall = []\n",
    "        threshold = []\n",
    "        n_positive_detections = 0\n",
    "        n_true_detected = 0\n",
    "        n_true_to_detect = len(true_boxes)\n",
    "        for i, (pred_bbox, proba) in enumerate(pred_boxes):\n",
    "            if len(true_boxes) > 0:\n",
    "                index, success = find_matching_bbox(pred_bbox, true_boxes, iou_threshold)\n",
    "                if success:\n",
    "                    true_boxes.pop(index)\n",
    "                    n_positive_detections += 1\n",
    "                    n_true_detected += 1\n",
    "\n",
    "            threshold.append(proba)\n",
    "            precision.append(n_positive_detections / (i +1))\n",
    "            recall.append(n_true_detected / n_true_to_detect)\n",
    "            \n",
    "\n",
    "        precisions[predicted_class] = precision\n",
    "        recalls[predicted_class] = recall\n",
    "        thresholds[predicted_class] = threshold\n",
    "\n",
    "    return precisions, recalls, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "def display_metrics(precisions, recalls):\n",
    "    classes = [\n",
    "        \"Primordial\", \n",
    "        \"Primary\",\n",
    "        \"Secondary\",\n",
    "        \"Tertiary\",\n",
    "    ]\n",
    "    colors = [\"navy\", \"turquoise\", \"darkorange\", \"cornflowerblue\", \"teal\"]\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(7, 8))\n",
    "\n",
    "    APs = {}\n",
    "    for class_to_predict, color in zip(classes, colors):\n",
    "        try:\n",
    "            precision = [1] + precisions[class_to_predict]\n",
    "            recall = [0] + recalls[class_to_predict]\n",
    "            average_precision = 0\n",
    "            for i in range(1, len(precision)):\n",
    "                average_precision += precision[i] * (recall[i] - recall[i-1])\n",
    "            APs[class_to_predict] = average_precision\n",
    "            display = PrecisionRecallDisplay(\n",
    "                recall=recall,\n",
    "                precision=precision,\n",
    "                average_precision=average_precision,\n",
    "                # linestyle=\"--\"\n",
    "            )\n",
    "            display.plot(ax=ax, name=f\"Precision-recall for class {class_to_predict}\", color=color, marker=\"o\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "    plt.show(ax)\n",
    "    return APs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = compute_precision_recall(true_locations=true_locations, predicted_locations=selected_locations_NMS, iou_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs = display_metrics(precisions, recalls)\n",
    "print(APs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average precision over the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_TO_ANALYSE = ['D-1M06-1.jpg', 'D-1M06-2.jpg', 'D-1M06-3.jpg', 'D-1M06-4.jpg', 'D-1M06-5.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for IMAGE_TO_ANALYSE in IMAGES_TO_ANALYSE:\n",
    "    section = Image.open(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE))\n",
    "    true_locations = load_true_locations(os.path.join(DATA_FOLDER, \"test\", 'labels.csv'), IMAGE_TO_ANALYSE)\n",
    "    display_section_and_locations(section, true_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true_locations_test = []\n",
    "#predicted_locations_test = []\n",
    "#for IMAGE_TO_ANALYSE in IMAGES_TO_ANALYSE:\n",
    "#    # load image\n",
    "#    section = Image.open(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE))\n",
    "#    # adding true locations to list for all test images\n",
    "#    true_locations_test += load_true_locations(os.path.join(DATA_FOLDER, \"test\", 'labels.csv'), IMAGE_TO_ANALYSE)\n",
    "#    # predicted locations for each image\n",
    "#    predicted_locations = []\n",
    "#    for width in [300, 800, 1000, 2000, 3000]:\n",
    "#        predicted_locations += predict_locations_for_windows(section, window_size=width, model=model, num_windows=1000)\n",
    "#    selected_locations = filter_predictions(predicted_locations, proba_threshold=0.80)\n",
    "#    selected_locations_NMS = NMS(selected_locations, iou_threshold=0.2)\n",
    "#    # adding predicted locations to list for all test images\n",
    "#    predicted_locations_test += selected_locations_NMS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_locations_test = []\n",
    "predicted_locations_test = []\n",
    "for IMAGE_TO_ANALYSE in IMAGES_TO_ANALYSE:\n",
    "    # load image\n",
    "    section = plt.imread(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE))\n",
    "    # adding true locations to list for all test images\n",
    "    true_locations_test += load_true_locations(os.path.join(DATA_FOLDER, \"test\", 'labels.csv'), IMAGE_TO_ANALYSE)\n",
    "    # predicted locations for each image\n",
    "    predicted_locations = predict_single_image(os.path.join(DATA_FOLDER, 'test', IMAGE_TO_ANALYSE), boxes_sizes=[2000,1500,1000], boxes_num = [1000,1000,1000])\n",
    "    selected_locations = filter_predictions(predicted_locations, proba_threshold=0.80)\n",
    "    selected_locations_NMS = NMS(selected_locations, iou_threshold=0.2)\n",
    "    # adding predicted locations to list for all test images\n",
    "    predicted_locations_test += selected_locations_NMS\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_locations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_locations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = compute_precision_recall(true_locations=true_locations_test, predicted_locations=predicted_locations_test, iou_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APs = display_metrics(precisions, recalls)\n",
    "print(APs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean Average Precision\n",
    "classes = [\n",
    "    \"Primordial\", \n",
    "    \"Primary\",\n",
    "    \"Secondary\",\n",
    "    \"Tertiary\",\n",
    "]\n",
    "APs_list = [APs[cl] for cl in classes]\n",
    "APs_list = np.array(APs_list)\n",
    "mAP = APs_list.mean()\n",
    "print(f\"mAP: {mAP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your proposition should at least beat this mAP score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick submission test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test any submission locally by running:\n",
    "\n",
    "```\n",
    "ramp-test --submission <submission folder>\n",
    "```\n",
    "If you want to quickly test the that there are no obvious code errors, use the `--quick-test` flag to only use a small subset of the data.\n",
    "\n",
    "```\n",
    "ramp-test --submission <submission folder> --quick-test\n",
    "```\n",
    "\n",
    "See the [online documentation](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/stable/using_kits.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [1,2,3]\n",
    "M = reversed(L)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4dc07e8789ff4ce2998d7d90953326abd22be7da9bd9ead53eceec85e6694ff3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
